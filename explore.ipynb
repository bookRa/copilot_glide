{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just locally running the notebook found at https://github.com/openai/glide-text2im/blob/main/notebooks/text2im.ipynb\n",
    "# !pip install git+https://github.com/openai/glide-text2im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "import torch as th\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version 1.9.0\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "print(\"torch version\", th.__version__)\n",
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glide_text2im.download import load_checkpoint\n",
    "from glide_text2im.model_creation import (\n",
    "    create_model_and_diffusion,\n",
    "    model_and_diffusion_defaults,\n",
    "    model_and_diffusion_defaults_upsampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# has_cuda = False\n",
    "has_cuda = th.cuda.is_available() # This sporadically me a CUDA: Out of Memory Error when True\n",
    "device = th.device('cuda' if has_cuda else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "options = model_and_diffusion_defaults()\n",
    "options['use_fp16'] = has_cuda\n",
    "options['timestep_respacing'] = '100'\n",
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total base parameters 385030726\n"
     ]
    }
   ],
   "source": [
    "model, diffusion = create_model_and_diffusion(**options)\n",
    "model.eval()\n",
    "if has_cuda:\n",
    "    model.convert_to_fp16()\n",
    "model.to(device)\n",
    "model.load_state_dict(load_checkpoint('base', device))\n",
    "print('total base parameters', sum(x.numel() for x in model.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |     806 MB |    2293 MB |    2293 MB |    1486 MB |\n",
      "|       from large pool |     765 MB |    2226 MB |    2226 MB |    1461 MB |\n",
      "|       from small pool |      40 MB |      66 MB |      66 MB |      25 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |     806 MB |    2293 MB |    2293 MB |    1486 MB |\n",
      "|       from large pool |     765 MB |    2226 MB |    2226 MB |    1461 MB |\n",
      "|       from small pool |      40 MB |      66 MB |      66 MB |      25 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    2334 MB |    2334 MB |    2334 MB |       0 B  |\n",
      "|       from large pool |    2266 MB |    2266 MB |    2266 MB |       0 B  |\n",
      "|       from small pool |      68 MB |      68 MB |      68 MB |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    7851 KB |  533869 KB |    2218 MB |    2210 MB |\n",
      "|       from large pool |    6232 KB |  527222 KB |    2157 MB |    2151 MB |\n",
      "|       from small pool |    1619 KB |    8396 KB |      60 MB |      59 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     783    |    1566    |    1566    |     783    |\n",
      "|       from large pool |     192    |     422    |     422    |     230    |\n",
      "|       from small pool |     591    |    1144    |    1144    |     553    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     783    |    1566    |    1566    |     783    |\n",
      "|       from large pool |     192    |     422    |     422    |     230    |\n",
      "|       from small pool |     591    |    1144    |    1144    |     553    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     140    |     140    |     140    |       0    |\n",
      "|       from large pool |     106    |     106    |     106    |       0    |\n",
      "|       from small pool |      34    |      34    |      34    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       7    |      47    |     207    |     200    |\n",
      "|       from large pool |       2    |      35    |     156    |     154    |\n",
      "|       from small pool |       5    |      13    |      51    |      46    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |     806 MB |    2293 MB |    2293 MB |    1486 MB |\n",
      "|       from large pool |     765 MB |    2226 MB |    2226 MB |    1461 MB |\n",
      "|       from small pool |      40 MB |      66 MB |      66 MB |      25 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |     806 MB |    2293 MB |    2293 MB |    1486 MB |\n",
      "|       from large pool |     765 MB |    2226 MB |    2226 MB |    1461 MB |\n",
      "|       from small pool |      40 MB |      66 MB |      66 MB |      25 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |     814 MB |    2334 MB |    2334 MB |    1520 MB |\n",
      "|       from large pool |     772 MB |    2266 MB |    2266 MB |    1494 MB |\n",
      "|       from small pool |      42 MB |      68 MB |      68 MB |      26 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    7851 KB |  533869 KB |    2218 MB |    2210 MB |\n",
      "|       from large pool |    6232 KB |  527222 KB |    2157 MB |    2151 MB |\n",
      "|       from small pool |    1619 KB |    8396 KB |      60 MB |      59 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     783    |    1566    |    1566    |     783    |\n",
      "|       from large pool |     192    |     422    |     422    |     230    |\n",
      "|       from small pool |     591    |    1144    |    1144    |     553    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     783    |    1566    |    1566    |     783    |\n",
      "|       from large pool |     192    |     422    |     422    |     230    |\n",
      "|       from small pool |     591    |    1144    |    1144    |     553    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      61    |     140    |     140    |      79    |\n",
      "|       from large pool |      40    |     106    |     106    |      66    |\n",
      "|       from small pool |      21    |      34    |      34    |      13    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       7    |      47    |     207    |     200    |\n",
      "|       from large pool |       2    |      35    |     156    |     154    |\n",
      "|       from small pool |       5    |      13    |      51    |      46    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "th.cuda.empty_cache()\n",
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_up = model_and_diffusion_defaults_upsampler()\n",
    "options_up['use_fp16'] = has_cuda\n",
    "options_up['timestep_respacing'] = 'fast27' # use 27 diffusion steps for very fast sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total upsampler parameters 398361286\n"
     ]
    }
   ],
   "source": [
    "model_up, diffusion_up = create_model_and_diffusion(**options_up)\n",
    "model_up.eval()\n",
    "if has_cuda:\n",
    "    model_up.convert_to_fp16()\n",
    "model_up.to(device)\n",
    "model_up.load_state_dict(load_checkpoint('upsample', device))\n",
    "# getting a GPU OOM unless cache is cleared\n",
    "# th.cuda.empty_cache()\n",
    "print('total upsampler parameters', sum(x.numel() for x in model_up.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1648 MB |    3184 MB |    4671 MB |    3022 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |    4542 MB |    2972 MB |\n",
      "|       from small pool |      78 MB |     102 MB |     128 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1648 MB |    3184 MB |    4671 MB |    3022 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |    4542 MB |    2972 MB |\n",
      "|       from small pool |      78 MB |     102 MB |     128 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    3228 MB |    3228 MB |    4748 MB |    1520 MB |\n",
      "|       from large pool |    3124 MB |    3124 MB |    4618 MB |    1494 MB |\n",
      "|       from small pool |     104 MB |     104 MB |     130 MB |      26 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    7220 KB |  700993 KB |    4338 MB |    4331 MB |\n",
      "|       from large pool |    5736 KB |  698550 KB |    4221 MB |    4215 MB |\n",
      "|       from small pool |    1484 KB |    9355 KB |     116 MB |     115 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1580    |    2377    |    3160    |    1580    |\n",
      "|       from large pool |     387    |     619    |     849    |     462    |\n",
      "|       from small pool |    1193    |    1758    |    2311    |    1118    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1580    |    2377    |    3160    |    1580    |\n",
      "|       from large pool |     387    |     619    |     849    |     462    |\n",
      "|       from small pool |    1193    |    1758    |    2311    |    1118    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     202    |     202    |     281    |      79    |\n",
      "|       from large pool |     150    |     150    |     216    |      66    |\n",
      "|       from small pool |      52    |      52    |      65    |      13    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      11    |      61    |     418    |     407    |\n",
      "|       from large pool |       3    |      47    |     318    |     315    |\n",
      "|       from small pool |       8    |      15    |     100    |      92    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(batch: th.Tensor):\n",
    "    \"\"\"Display a batch of images inline.\"\"\"\n",
    "    scaled = ((batch + 1)*127.5).round().clamp(0,255).to(th.uint8).cpu()\n",
    "    reshaped = scaled.permute(2, 0, 3, 1).reshape([batch.shape[2], -1, 3])\n",
    "    display(Image.fromarray(reshaped.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling parameters\n",
    "prompt = \"an oil painting of a corgi\"\n",
    "batch_size = 1\n",
    "guidance_scale = 3.0\n",
    "\n",
    "# Tune this parameter to control the sharpness of 256x256 images.\n",
    "# a value of 1.0 is sharper but sometimes results in grainy artifacts.\n",
    "upsample_temp = 0.997"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Sample from the base model\n",
    "\n",
    "# Create the text tokens to feed to the model.\n",
    "tokens = model.tokenizer.encode(prompt)\n",
    "tokens, mask = model.tokenizer.padded_tokens_and_mask(tokens, options['text_ctx'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1648 MB |    3184 MB |    4671 MB |    3022 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |    4542 MB |    2972 MB |\n",
      "|       from small pool |      78 MB |     102 MB |     128 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1648 MB |    3184 MB |    4671 MB |    3022 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |    4542 MB |    2972 MB |\n",
      "|       from small pool |      78 MB |     102 MB |     128 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    3228 MB |    3228 MB |    4748 MB |    1520 MB |\n",
      "|       from large pool |    3124 MB |    3124 MB |    4618 MB |    1494 MB |\n",
      "|       from small pool |     104 MB |     104 MB |     130 MB |      26 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    7220 KB |  700993 KB |    4338 MB |    4331 MB |\n",
      "|       from large pool |    5736 KB |  698550 KB |    4221 MB |    4215 MB |\n",
      "|       from small pool |    1484 KB |    9355 KB |     116 MB |     115 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1580    |    2377    |    3160    |    1580    |\n",
      "|       from large pool |     387    |     619    |     849    |     462    |\n",
      "|       from small pool |    1193    |    1758    |    2311    |    1118    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1580    |    2377    |    3160    |    1580    |\n",
      "|       from large pool |     387    |     619    |     849    |     462    |\n",
      "|       from small pool |    1193    |    1758    |    2311    |    1118    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     202    |     202    |     281    |      79    |\n",
      "|       from large pool |     150    |     150    |     216    |      66    |\n",
      "|       from small pool |      52    |      52    |      65    |      13    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      11    |      61    |     418    |     407    |\n",
      "|       from large pool |       3    |      47    |     318    |     315    |\n",
      "|       from small pool |       8    |      15    |     100    |      92    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the classifier-free guidance tokens (empty)\n",
    "full_batch_size = batch_size * 2\n",
    "uncond_tokens, uncond_mask = model.tokenizer.padded_tokens_and_mask( [], options['text_ctx'])\n",
    "\n",
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1648 MB |    3184 MB |    4671 MB |    3022 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |    4542 MB |    2972 MB |\n",
      "|       from small pool |      78 MB |     102 MB |     128 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1648 MB |    3184 MB |    4671 MB |    3022 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |    4542 MB |    2972 MB |\n",
      "|       from small pool |      78 MB |     102 MB |     128 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    3228 MB |    3228 MB |    4748 MB |    1520 MB |\n",
      "|       from large pool |    3124 MB |    3124 MB |    4618 MB |    1494 MB |\n",
      "|       from small pool |     104 MB |     104 MB |     130 MB |      26 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    7217 KB |  700993 KB |    4338 MB |    4331 MB |\n",
      "|       from large pool |    5736 KB |  698550 KB |    4221 MB |    4215 MB |\n",
      "|       from small pool |    1481 KB |    9355 KB |     116 MB |     115 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1582    |    2377    |    3162    |    1580    |\n",
      "|       from large pool |     387    |     619    |     849    |     462    |\n",
      "|       from small pool |    1195    |    1758    |    2313    |    1118    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1582    |    2377    |    3162    |    1580    |\n",
      "|       from large pool |     387    |     619    |     849    |     462    |\n",
      "|       from small pool |    1195    |    1758    |    2313    |    1118    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     202    |     202    |     281    |      79    |\n",
      "|       from large pool |     150    |     150    |     216    |      66    |\n",
      "|       from small pool |      52    |      52    |      65    |      13    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      10    |      61    |     418    |     408    |\n",
      "|       from large pool |       3    |      47    |     318    |     315    |\n",
      "|       from small pool |       7    |      15    |     100    |      93    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Pack the tokens together into model kwargs.\n",
    "model_kwargs = dict(\n",
    "    tokens = th.tensor([tokens] * batch_size + [uncond_tokens] * batch_size, device = device),\n",
    "    mask = th.tensor([mask] * batch_size + [uncond_mask] * batch_size, device = device, dtype=th.bool),\n",
    ")\n",
    "\n",
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1648 MB |    3184 MB |    4671 MB |    3022 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |    4542 MB |    2972 MB |\n",
      "|       from small pool |      78 MB |     102 MB |     128 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1648 MB |    3184 MB |    4671 MB |    3022 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |    4542 MB |    2972 MB |\n",
      "|       from small pool |      78 MB |     102 MB |     128 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    1656 MB |    3228 MB |    4748 MB |    3092 MB |\n",
      "|       from large pool |    1576 MB |    3124 MB |    4618 MB |    3042 MB |\n",
      "|       from small pool |      80 MB |     104 MB |     130 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    7217 KB |  700993 KB |    4338 MB |    4331 MB |\n",
      "|       from large pool |    5736 KB |  698550 KB |    4221 MB |    4215 MB |\n",
      "|       from small pool |    1481 KB |    9355 KB |     116 MB |     115 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1582    |    2377    |    3162    |    1580    |\n",
      "|       from large pool |     387    |     619    |     849    |     462    |\n",
      "|       from small pool |    1195    |    1758    |    2313    |    1118    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1582    |    2377    |    3162    |    1580    |\n",
      "|       from large pool |     387    |     619    |     849    |     462    |\n",
      "|       from small pool |    1195    |    1758    |    2313    |    1118    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     124    |     202    |     281    |     157    |\n",
      "|       from large pool |      84    |     150    |     216    |     132    |\n",
      "|       from small pool |      40    |      52    |      65    |      25    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      10    |      61    |     418    |     408    |\n",
      "|       from large pool |       3    |      47    |     318    |     315    |\n",
      "|       from small pool |       7    |      15    |     100    |      93    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(th.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b801aa391c734bf8a7ab39a7f8eb7ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Create a classifier-free guidance sampling function\n",
    "\n",
    "def model_fn(x_t, ts, **kwargs):\n",
    "    half = x_t[: len(x_t) //2]\n",
    "    combined = th.cat([half, half], dim = 0)\n",
    "    model_out = model(combined, ts, **kwargs)\n",
    "    eps, rest = model_out[:, :3], model_out[:, 3:]\n",
    "    cond_eps, uncond_eps = th.split(eps, len(eps) // 2, dim = 0)\n",
    "    half_eps = uncond_eps + guidance_scale * (cond_eps - uncond_eps)\n",
    "    eps = th.cat([half_eps, half_eps], dim = 0)\n",
    "    return th.cat([eps, rest], dim = 1)\n",
    "\n",
    "# Sample from the base model\n",
    "model.del_cache()\n",
    "samples = diffusion.p_sample_loop(\n",
    "    model_fn,\n",
    "    (full_batch_size, 3, options[\"image_size\"], options[\"image_size\"]),\n",
    "    device=device,\n",
    "    clip_denoised=True,\n",
    "    progress=True,\n",
    "    model_kwargs=model_kwargs,\n",
    "    cond_fn=None,\n",
    ")[:batch_size]\n",
    "model.del_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F1E9C5FCFD0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "show_images(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |    1649 MB |    3184 MB |  373599 MB |  371950 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |  332776 MB |  331205 MB |\n",
      "|       from small pool |      78 MB |     102 MB |   40823 MB |   40745 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |    1649 MB |    3184 MB |  373599 MB |  371950 MB |\n",
      "|       from large pool |    1570 MB |    3081 MB |  332776 MB |  331205 MB |\n",
      "|       from small pool |      78 MB |     102 MB |   40823 MB |   40745 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |    1842 MB |    3228 MB |    4934 MB |    3092 MB |\n",
      "|       from large pool |    1752 MB |    3124 MB |    4794 MB |    3042 MB |\n",
      "|       from small pool |      90 MB |     104 MB |     140 MB |      50 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |    7121 KB |  700993 KB |  328328 MB |  328321 MB |\n",
      "|       from large pool |    5736 KB |  698550 KB |  279660 MB |  279654 MB |\n",
      "|       from small pool |    1385 KB |    9355 KB |   48668 MB |   48667 MB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |    1583    |    2377    |  217068    |  215485    |\n",
      "|       from large pool |     387    |     619    |   58449    |   58062    |\n",
      "|       from small pool |    1196    |    1758    |  158619    |  157423    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |    1583    |    2377    |  217068    |  215485    |\n",
      "|       from large pool |     387    |     619    |   58449    |   58062    |\n",
      "|       from small pool |    1196    |    1758    |  158619    |  157423    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |     134    |     202    |     291    |     157    |\n",
      "|       from large pool |      89    |     150    |     221    |     132    |\n",
      "|       from small pool |      45    |      52    |      70    |      25    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      10    |      61    |  102382    |  102372    |\n",
      "|       from large pool |       3    |      47    |   30918    |   30915    |\n",
      "|       from small pool |       7    |      15    |   71464    |   71457    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(th.cuda.memory_summary())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "36fd232ae0ec2bce823ce5f9d3fd67e4db9a15f1eaff904e6293626434c24bc0"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cognascent': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
